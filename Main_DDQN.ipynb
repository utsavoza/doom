{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7422d8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating game environment ...\n",
      "Game environment initialized ...\n",
      "Using device=cuda ...\n",
      "Initializing New Model\n",
      "\n",
      "Epoch #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:02<00:00, 11.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results (Train): mean: -174.0 +/- 151.0, min: -325.0, max: -23.0,\n",
      "\n",
      "Testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results (Test): mean: -159.9 +/- 155.4, min: -340.0 max: 62.0\n",
      "Saving the network weights to: checkpoints/Doom_DoubleDQN.pth\n",
      "Total elapsed time: 0.19 minutes\n",
      "======================================\n",
      "Training finished. It's time to watch!\n",
      "Total score:  -304.0\n",
      "Total score:  -322.0\n",
      "Total score:  -95.0\n",
      "Total score:  -82.0\n",
      "Total score:  -315.0\n",
      "Total score:  -325.0\n",
      "Total score:  -165.0\n",
      "Total score:  69.0\n",
      "Total score:  -310.0\n",
      "Total score:  79.0\n"
     ]
    }
   ],
   "source": [
    "import itertools as it\n",
    "import os\n",
    "from time import time, sleep\n",
    "\n",
    "import torch\n",
    "import vizdoom as vzd\n",
    "import skimage\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "\n",
    "from DoubleDQNAgent import DoubleDQNAgent\n",
    "\n",
    "\n",
    "def preprocess(img):\n",
    "    \"\"\"Down samples image to resolution\"\"\"\n",
    "    img = skimage.transform.resize(img, (30, 45))\n",
    "    img = img.astype(np.float32)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "\n",
    "def create_game_environment(config_file_path):\n",
    "    print(\"Creating game environment ...\")\n",
    "    game = vzd.DoomGame()\n",
    "    game.load_config(config_file_path)\n",
    "    game.set_window_visible(False)\n",
    "    game.set_mode(vzd.Mode.PLAYER)\n",
    "    game.set_screen_format(vzd.ScreenFormat.GRAY8)\n",
    "    game.set_screen_resolution(vzd.ScreenResolution.RES_640X480)\n",
    "    game.init()\n",
    "    print(\"Game environment initialized ...\")\n",
    "    return game\n",
    "\n",
    "\n",
    "def test_agent(game, agent, actions, frame_repeat, test_episodes_per_epoch=10):\n",
    "    \"\"\"Runs a test_episodes_per_epoch episodes and prints the result\"\"\"\n",
    "    print(\"\\nTesting...\")\n",
    "    test_scores = []\n",
    "    for _ in trange(test_episodes_per_epoch, leave=False):\n",
    "        game.new_episode()\n",
    "        while not game.is_episode_finished():\n",
    "            state = preprocess(game.get_state().screen_buffer)\n",
    "            best_action_index = agent.get_action(state)\n",
    "            game.make_action(actions[best_action_index], frame_repeat)\n",
    "        reward = game.get_total_reward()\n",
    "        test_scores.append(reward)\n",
    "\n",
    "    test_scores = np.array(test_scores)\n",
    "    return test_scores\n",
    "\n",
    "\n",
    "def train_agent(game, agent, actions, num_epochs, frame_repeat, steps_per_epoch, save_model, model_path):\n",
    "    \"\"\"\n",
    "    Trains the DQN Agent by running num_epochs of training episodes.\n",
    "    Skip frame_repeat number of frames after each action.\n",
    "    \"\"\"\n",
    "\n",
    "    start_time = time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        game.new_episode()\n",
    "        train_scores = []\n",
    "        global_step = 0\n",
    "\n",
    "        print(\"\\nEpoch #\" + str(epoch + 1))\n",
    "\n",
    "        for _ in trange(steps_per_epoch):\n",
    "            state = preprocess(game.get_state().screen_buffer)\n",
    "            action = agent.get_action(state)\n",
    "            reward = game.make_action(actions[action], frame_repeat)\n",
    "            done = game.is_episode_finished()\n",
    "\n",
    "            if not done:\n",
    "                next_state = preprocess(game.get_state().screen_buffer)\n",
    "            else:\n",
    "                next_state = np.zeros((1, 30, 45)).astype(np.float32)\n",
    "\n",
    "            agent.append_memory(state, action, reward, next_state, done)\n",
    "\n",
    "            if global_step > agent.batch_size:\n",
    "                agent.train()\n",
    "\n",
    "            if done:\n",
    "                train_scores.append(game.get_total_reward())\n",
    "                game.new_episode()\n",
    "\n",
    "            global_step += 1\n",
    "\n",
    "        train_scores = np.array(train_scores)\n",
    "        print(\n",
    "            \"Results (Train): mean: {:.1f} +/- {:.1f},\".format(\n",
    "                train_scores.mean(), train_scores.std()\n",
    "            ),\n",
    "            \"min: %.1f,\" % train_scores.min(),\n",
    "            \"max: %.1f,\" % train_scores.max(),\n",
    "        )\n",
    "\n",
    "        test_scores = test_agent(game, agent, actions, frame_repeat)\n",
    "        print(\n",
    "            \"Results (Test): mean: {:.1f} +/- {:.1f},\".format(\n",
    "                test_scores.mean(), test_scores.std()\n",
    "            ),\n",
    "            \"min: %.1f\" % test_scores.min(),\n",
    "            \"max: %.1f\" % test_scores.max(),\n",
    "        )\n",
    "\n",
    "        if save_model:\n",
    "            print(\"Saving the network weights to:\", model_path)\n",
    "            torch.save(agent.q_net, model_path)\n",
    "        print(\"Total elapsed time: %.2f minutes\" %\n",
    "              ((time() - start_time) / 60.0))\n",
    "\n",
    "    game.close()\n",
    "    return agent, game\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config_file_path = os.path.join(vzd.scenarios_path, \"rocket_basic.cfg\")\n",
    "    game = create_game_environment(config_file_path)\n",
    "    n = game.get_available_buttons_size()\n",
    "    actions = [list(a) for a in it.product([0, 1], repeat=n)]\n",
    "    \n",
    "      \n",
    "\n",
    "    # Set the hyperparameters\n",
    "    batch_size = 32\n",
    "    lr = 0.0021736400029288543\n",
    "    discount_factor = 0.9107590426615555\n",
    "    memory_size = 10000\n",
    "    frame_repeat = 16\n",
    "    steps_per_epoch = 30\n",
    "    epsilon_decay = 0.9945794627225366\n",
    "\n",
    "    # Use GPU if available\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    print(f\"Using device={device} ...\")\n",
    "\n",
    "    # Initialize our agent with the set parameters\n",
    "    agent = DoubleDQNAgent(\n",
    "        action_size=len(actions),\n",
    "        lr=lr,\n",
    "        batch_size=batch_size,\n",
    "        memory_size=memory_size,\n",
    "        discount_factor=discount_factor,\n",
    "        device=device,\n",
    "        load_model=False,\n",
    "        optimizer = \"Adam\",\n",
    "        epsilon_decay=epsilon_decay\n",
    "        \n",
    "    )\n",
    "\n",
    "    # Run the training for the set number of epochs\n",
    "    skip_learning = False\n",
    "    if not skip_learning:\n",
    "        agent, game = train_agent(\n",
    "            game,\n",
    "            agent,\n",
    "            actions,\n",
    "            num_epochs=1,\n",
    "            frame_repeat=frame_repeat,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            save_model=True,\n",
    "            model_path=\"checkpoints/Doom_DoubleDQN.pth\"\n",
    "        )\n",
    "\n",
    "        print(\"======================================\")\n",
    "        print(\"Training finished. It's time to watch!\")\n",
    "\n",
    "    # Reinitialize the game with window visible\n",
    "    game.close()\n",
    "    game.set_window_visible(True)\n",
    "    game.set_mode(vzd.Mode.ASYNC_PLAYER)\n",
    "    game.init()\n",
    "\n",
    "    for _ in range(10):\n",
    "        game.new_episode()\n",
    "        while not game.is_episode_finished():\n",
    "            state = preprocess(game.get_state().screen_buffer)\n",
    "            best_action_index = agent.get_action(state)\n",
    "\n",
    "            # Instead of make_action(a, frame_repeat) in order to make the animation smooth\n",
    "            game.set_action(actions[best_action_index])\n",
    "            for _ in range(12):\n",
    "                game.advance_action()\n",
    "\n",
    "        # Sleep between episodes\n",
    "        sleep(1.0)\n",
    "        score = game.get_total_reward()\n",
    "        print(\"Total score: \", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373ac34d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
